{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca6d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from loguru import logger\n",
    "\n",
    "class AudioGenerator:\n",
    "    \"\"\"\n",
    "    Extracts audio from a video and segments it according to timestamps.\n",
    "    Segments are saved as .wav files in a temporary directory.\n",
    "    \"\"\"\n",
    "    def __init__(self, video_path: str, tmp_audio_dir: str = \"tmp_audio\"):\n",
    "        self.video_path = video_path\n",
    "        self.tmp_audio_dir = Path(tmp_audio_dir)\n",
    "        self.tmp_audio_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def extract_segments(self, segments: List[Dict[str, Any]],\n",
    "                        sample_rate: int = 16000) -> List[str]:\n",
    "        \"\"\"\n",
    "        For each segment (with start_time, end_time), extract audio and save as wav.\n",
    "        Returns list of audio file paths.\n",
    "        \"\"\"\n",
    "        audio_paths = []\n",
    "        for idx, seg in enumerate(segments):\n",
    "            start = self._parse_time(seg['start_time'])\n",
    "            end = self._parse_time(seg.get('end_time'))\n",
    "            duration = max(0.1, end - start) if end > start else 3.0\n",
    "            out_path = self.tmp_audio_dir / f\"segment_{idx:04d}.wav\"\n",
    "            print(\"*****\")\n",
    "            print(out_path)\n",
    "\n",
    "            cmd = [\n",
    "                \"ffmpeg\", \"-y\", \"-i\", str(self.video_path),\n",
    "                \"-ss\", f\"{start:.3f}\", \"-t\", f\"{duration:.3f}\",\n",
    "                \"-ar\", str(sample_rate), \"-ac\", \"1\", \"-vn\", str(out_path),\n",
    "                \"-loglevel\", \"error\"\n",
    "            ]\n",
    "            result = subprocess.run(cmd)\n",
    "            print(result)\n",
    "            if result.returncode == 0 and out_path.exists():\n",
    "                audio_paths.append(str(out_path))\n",
    "            else:\n",
    "                logger.error(f\"Failed to extract audio segment {idx} ({start}-{end})\")\n",
    "                audio_paths.append(\"\")\n",
    "        return audio_paths\n",
    "\n",
    "    def _parse_time(self, t: str) -> float:\n",
    "        if not t:\n",
    "            return 0.0\n",
    "        t = t.replace(\",\", \".\")\n",
    "        parts = t.split(\":\")\n",
    "        if len(parts) == 2:\n",
    "            minutes, rest = parts\n",
    "            seconds, ms = rest.split(\".\") if \".\" in rest else (rest, \"0\")\n",
    "            return int(minutes) * 60 + int(seconds) + int(ms) / 1000\n",
    "        elif len(parts) == 3:\n",
    "            hours, minutes, rest = parts\n",
    "            seconds, ms = rest.split(\".\") if \".\" in rest else (rest, \"0\")\n",
    "            return int(hours) * 3600 + int(minutes) * 60 + int(seconds) + int(ms) / 1000\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e9e3c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sawal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "from pathlib import Path\n",
    "import json\n",
    "from loguru import logger\n",
    "from datasets import Dataset, Audio, Features, Value\n",
    "\n",
    "class HuggingfaceCooker:\n",
    "    \"\"\"A class to prepare and upload datasets to Huggingface Hub.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        token: Optional[str] = None,\n",
    "        repository_id: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the Huggingface Cooker.\n",
    "        \n",
    "        Args:\n",
    "            token: Huggingface API token (optional if not pushing to hub)\n",
    "            repository_id: Repository ID to push to (optional)\n",
    "        \"\"\"\n",
    "        self.token = token\n",
    "        self.repository_id = repository_id\n",
    "    \n",
    "    def cook_dataset(\n",
    "        self,\n",
    "        ocr_results: List[Dict[str, Any]],\n",
    "        video_path: str,\n",
    "        output_dir: str,\n",
    "        push_to_hub: bool = False,\n",
    "        private: bool = False\n",
    "    ) -> Dataset:\n",
    "        \"\"\"\n",
    "        Cook a Huggingface dataset from OCR results and video file.\n",
    "        \n",
    "        Args:\n",
    "            ocr_results: List of OCR results with timestamps and text\n",
    "            video_path: Path to the video file\n",
    "            output_dir: Directory to save the prepared dataset\n",
    "            push_to_hub: Whether to push the dataset to Huggingface Hub\n",
    "            \n",
    "        Returns:\n",
    "            The created Huggingface Dataset\n",
    "        \"\"\"\n",
    "        try:\n",
    "            output_dir = Path(output_dir)\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            audio_gen = AudioGenerator(video_path, tmp_audio_dir=output_dir/\"tmp_audio\")\n",
    "            audio_paths = audio_gen.extract_segments(ocr_results)\n",
    "            \n",
    "            dataset_items = []\n",
    "            for entry, audio_path in zip(ocr_results, audio_paths):\n",
    "                if not entry.get('success', False):\n",
    "                    continue\n",
    "                \n",
    "                text = entry.get('text', '').strip()\n",
    "                if not text or not audio_path:\n",
    "                    continue\n",
    "                \n",
    "                start_time = entry.get('start_time', entry.get('time_formatted', ''))\n",
    "                \n",
    "                dataset_items.append({\n",
    "                    'audio': str(audio_path),\n",
    "                    'text': text,\n",
    "                    'start_time': start_time\n",
    "                })\n",
    "            \n",
    "            features = Features({\n",
    "                'audio': Audio(),\n",
    "                'text': Value('string'),\n",
    "                'start_time': Value('string')\n",
    "            })\n",
    "            \n",
    "            dataset = Dataset.from_list(dataset_items, features=features)\n",
    "            \n",
    "            dataset.save_to_disk(str(output_dir))\n",
    "            logger.info(f\"✅ Successfully created dataset with {len(dataset)} entries\")\n",
    "            \n",
    "            if push_to_hub and self.token:\n",
    "                dataset.push_to_hub(\n",
    "                    repo_id=self.repository_id,\n",
    "                    token=self.token,\n",
    "                    private=private \n",
    "                )\n",
    "                logger.info(f\"✅ Successfully pushed dataset to {self.repository_id}\")\n",
    "            \n",
    "            return dataset\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"❌ Error cooking dataset: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36ea1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "C:\\Users\\sawal\\Desktop\\project X\\Frame2Text4LLM\\sandbox\\tmp_audio\\segment_0000.wav\n",
      "CompletedProcess(args=['ffmpeg', '-y', '-i', 'C:/Users/sawal/Desktop/project X/Frame2Text4LLM/sandbox/sample_short.mp4', '-ss', '5.000', '-t', '5.000', '-ar', '16000', '-ac', '1', '-vn', 'C:\\\\Users\\\\sawal\\\\Desktop\\\\project X\\\\Frame2Text4LLM\\\\sandbox\\\\tmp_audio\\\\segment_0000.wav', '-loglevel', 'error'], returncode=0)\n",
      "*****\n",
      "C:\\Users\\sawal\\Desktop\\project X\\Frame2Text4LLM\\sandbox\\tmp_audio\\segment_0001.wav\n",
      "CompletedProcess(args=['ffmpeg', '-y', '-i', 'C:/Users/sawal/Desktop/project X/Frame2Text4LLM/sandbox/sample_short.mp4', '-ss', '11.000', '-t', '159.000', '-ar', '16000', '-ac', '1', '-vn', 'C:\\\\Users\\\\sawal\\\\Desktop\\\\project X\\\\Frame2Text4LLM\\\\sandbox\\\\tmp_audio\\\\segment_0001.wav', '-loglevel', 'error'], returncode=0)\n",
      "*****\n",
      "C:\\Users\\sawal\\Desktop\\project X\\Frame2Text4LLM\\sandbox\\tmp_audio\\segment_0002.wav\n",
      "CompletedProcess(args=['ffmpeg', '-y', '-i', 'C:/Users/sawal/Desktop/project X/Frame2Text4LLM/sandbox/sample_short.mp4', '-ss', '171.000', '-t', '69.000', '-ar', '16000', '-ac', '1', '-vn', 'C:\\\\Users\\\\sawal\\\\Desktop\\\\project X\\\\Frame2Text4LLM\\\\sandbox\\\\tmp_audio\\\\segment_0002.wav', '-loglevel', 'error'], returncode=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 89.16 examples/s] \n",
      "\u001b[32m2025-07-07 00:31:46.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcook_dataset\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1m✅ Successfully created dataset with 3 entries\u001b[0m\n",
      "Map: 100%|██████████| 3/3 [00:00<00:00, 161.02 examples/s]?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 37.37ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "c:\\Users\\sawal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sawal\\.cache\\huggingface\\hub\\datasets--sawadogosalif--Frame2Text4LLM. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "\u001b[32m2025-07-07 00:31:48.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcook_dataset\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1m✅ Successfully pushed dataset to Frame2Text4LLM\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "ocr_results = [\n",
    "    {\n",
    "        \"success\": True,\n",
    "        \"text\": \"Bonjour, ceci est le début de la vidéo.\",\n",
    "        \"start_time\": \"00:00:05\",\n",
    "        \"end_time\": \"00:00:10\"\n",
    "    },\n",
    "    {\n",
    "        \"success\": True,\n",
    "        \"text\": \"Voici une autre phrase extraite à la minute 2.\",\n",
    "        \"start_time\": \"00:00:11\",\n",
    "        \"end_time\": \"00:02:50\"\n",
    "    },\n",
    "    {\n",
    "        \"success\": True,\n",
    "        \"text\": \"Fin de la vidéo, merci de votre attention.\",\n",
    "        \"start_time\": \"00:02:51\",\n",
    "        \"end_time\": \"00:04:00\"\n",
    "    }\n",
    "]\n",
    "\n",
    "video_path = r\"C:/Users/sawal/Desktop/project X/Frame2Text4LLM/sandbox/sample_short.mp4\"\n",
    "output_dir = r'C:/Users/sawal/Desktop/project X/Frame2Text4LLM/sandbox'\n",
    "\n",
    "cooker = HuggingfaceCooker(token=os.environ[\"HF_TOKEN\"], repository_id=\"Frame2Text4LLM\")\n",
    "dataset = cooker.cook_dataset(\n",
    "    ocr_results=ocr_results,\n",
    "    video_path=video_path,\n",
    "    output_dir=output_dir,\n",
    "    push_to_hub=True  \n",
    ")\n",
    "print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6429bc77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
